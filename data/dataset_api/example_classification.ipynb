{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets API usage example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "\n",
    "core = Core()\n",
    "model = core.read_model('SampLeNet.xml')\n",
    "compiled_model = core.compile_model(model, 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create datset, preprocessings, postprocessing and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation conversion for cifar10 dataset has been started\n",
      "Parameters to be used for conversion:\n",
      "converter: cifar\n",
      "data_batch_file: cifar-10-batches-py\\test_batch\n",
      "convert_images: True\n",
      "converted_images_dir: cifar-10-batches-py\\test\n",
      "num_classes: 10\n",
      "Annotation conversion for cifar10 dataset has been finished\n"
     ]
    }
   ],
   "source": [
    "from openvino.model_zoo.datasets import CIFAR10Dataset\n",
    "from openvino.model_zoo.transforms.input import pillow_resize, normalization, transpose\n",
    "from openvino.model_zoo.metrics import create_accuracy\n",
    "from openvino.model_zoo.transforms.output import ClassificationPostprocessor\n",
    "\n",
    "# just for demonstration that any other custom transforms accepted\n",
    "def expand_dim(image, **kwargs):\n",
    "    image.data = np.expand_dims(image.data, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    pillow_resize(size=32), \n",
    "    normalization(mean=[125.307, 122.961, 113.8575], std=[51.5865, 50.847, 51.255]),\n",
    "    transpose([2, 0, 1]),\n",
    "    expand_dim\n",
    "]\n",
    "\n",
    "dataset_iterator = CIFAR10Dataset('cifar-10-batches-py', transforms=transforms, reader='pillow_imread')\n",
    "postprocessor = ClassificationPostprocessor(compiled_model.outputs[0])\n",
    "\n",
    "accuracy = create_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Infer model on dataset in sync mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.7502\n"
     ]
    }
   ],
   "source": [
    "infer_request = compiled_model.create_infer_request()\n",
    "for (batch_input_ids, batch_annotation, batch_input, batch_meta, _) in dataset_iterator:\n",
    "    infer_result = infer_request.infer(batch_input)\n",
    "    batch_predictions = postprocessor(infer_result, batch_meta, batch_input_ids)\n",
    "    accuracy.batch_update(batch_annotation, batch_predictions)\n",
    "\n",
    "print(f'Model accuracy: {accuracy.evaluate()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dataset API and AsyncInferQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.7502\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import AsyncInferQueue\n",
    "\n",
    "accuracy.reset()\n",
    "infer_queue = AsyncInferQueue(compiled_model, 2)\n",
    "def completion_callback(request, user_data):\n",
    "    batch_id, batch_identifiers, batch_annotations, batch_meta = user_data\n",
    "    infer_results = request.results\n",
    "    batch_predictions = postprocessor(infer_results, batch_meta, batch_identifiers)\n",
    "    accuracy.batch_update(batch_annotations, batch_predictions)\n",
    "\n",
    "infer_queue.set_callback(completion_callback)\n",
    "for (batch_input_ids, batch_annotation, batch_input, batch_meta, batch_identifiers) in dataset_iterator:\n",
    "    infer_queue.start_async(batch_input, (batch_input_ids, batch_identifiers, batch_annotation, batch_meta))\n",
    "infer_queue.wait_all()\n",
    "\n",
    "print(f'Model accuracy: {accuracy.evaluate()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input transforms from frameworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.7502\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from openvino.model_zoo.transforms.input import from_torch\n",
    "\n",
    "input_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(\n",
    "        mean=[125.307 / 255, 122.961 / 255, 113.8575 / 255], \n",
    "        std=[51.5865 / 255, 50.847 / 255, 51.255 / 255])\n",
    "    ])\n",
    "\n",
    "transforms = [\n",
    "    from_torch(input_transforms)\n",
    "]\n",
    "dataset_iterator.reset()\n",
    "dataset_iterator.set_transforms(transforms)\n",
    "\n",
    "for (batch_input_ids, batch_annotation, batch_input, batch_meta, batch_identifiers) in dataset_iterator:\n",
    "    infer_result = infer_request.infer([np.array(batch_input)])\n",
    "    batch_predictions = postprocessor(infer_result, batch_meta, batch_identifiers)\n",
    "    accuracy.batch_update(batch_annotation, batch_predictions)\n",
    "\n",
    "print(f'Model accuracy: {accuracy.evaluate()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model quantization with POT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import addict\n",
    "from openvino.tools.pot import IEEngine, save_model, compress_model_weights, create_pipeline, load_model\n",
    "from openvino.tools.pot.engines.utils import process_raw_output\n",
    "postprocessor.output_tensor = 'fc3'\n",
    "\n",
    "algorithms = [\n",
    "        {\n",
    "            'name': 'DefaultQuantization',\n",
    "            'params': {\n",
    "                'target_device': 'ANY',\n",
    "                'preset': 'performance',\n",
    "                'stat_subset_size': 300\n",
    "            }\n",
    "        }\n",
    "]\n",
    "\n",
    "model_config = addict.Dict({\n",
    "        'model_name': 'sample_model',\n",
    "        'model': 'SampLeNet.xml',\n",
    "        'weights': 'SampLeNet.bin'\n",
    "})\n",
    "\n",
    "engine_config = addict.Dict({\n",
    "        'device': 'CPU',\n",
    "        'stat_requests_number': 4,\n",
    "        'eval_requests_number': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine(IEEngine):\n",
    "    def _process_infer_output(self, stats_layout, predictions,\n",
    "                              batch_annotations, batch_meta, need_metrics_per_sample):\n",
    "        # Collect statistics\n",
    "        if stats_layout:\n",
    "            self._collect_statistics(outputs=predictions,\n",
    "                                     stats_layout=stats_layout,\n",
    "                                     annotations=batch_annotations)\n",
    "\n",
    "        # Postprocess network output\n",
    "        outputs = process_raw_output(predictions)\n",
    "        output = outputs[self._output_layers[0]] #outputs['fc3']\n",
    "        outputs[self._output_layers[0]] = self.postprocess_output(output, batch_meta)\n",
    "\n",
    "        # Update metrics\n",
    "        if batch_annotations:\n",
    "            logits = postprocessor(outputs, batch_meta)\n",
    "            self._update_metrics(output=logits, annotations=batch_annotations,\n",
    "                                 need_metrics_per_sample=need_metrics_per_sample)\n",
    "    \n",
    "    def _process_batch(self, batch):\n",
    "        _batch = batch[0]\n",
    "        batch_ids, batch_annotation, batch_input, batch_meta = _batch[0], _batch[1], _batch[2], _batch[3]\n",
    "\n",
    "        return list(zip(batch_ids, batch_annotation)), batch_input, batch_meta\n",
    "\n",
    "    def _update_metrics(self, output, annotations, need_metrics_per_sample=False):\n",
    "        \"\"\" Updates metrics.\n",
    "        :param output: network output\n",
    "        :param annotations: a list of annotations for metrics collection [(img_id, annotation)]\n",
    "        :param need_metrics_per_sample: whether to collect metrics for each batch\n",
    "        \"\"\"\n",
    "        annotations_are_valid = all(a is not None for a in annotations)\n",
    "\n",
    "        if self._metric and annotations_are_valid:\n",
    "            for out, (sample_id, ann) in zip(output, annotations):\n",
    "                self._metric.update(ann, out)\n",
    "                if need_metrics_per_sample:\n",
    "                    metrics = self._metric.value\n",
    "                    for metric_name, metric_value in metrics.items():\n",
    "                        self._per_sample_metrics.append({'sample_id': sample_id,\n",
    "                                                        'metric_name': metric_name,\n",
    "                                                        'result': metric_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = Engine(engine_config, dataset_iterator, accuracy)\n",
    "pipeline = create_pipeline(algorithms, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rep = load_model(model_config)\n",
    "compressed_model = pipeline.run(model_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'optimized\\\\SampLeNet.xml', 'weights': 'optimized\\\\SampLeNet.bin'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_model_weights(compressed_model)\n",
    "save_model(compressed_model, 'optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None: array(0.7413)}\n"
     ]
    }
   ],
   "source": [
    "metric_results = pipeline.evaluate(compressed_model)\n",
    "print(metric_results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de7950e2c7f59756e69470654cad4361df158ed1ba671081876ae2b683d5c84"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
