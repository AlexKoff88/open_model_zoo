{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following steps in order:\n",
    "\n",
    "1. Create PyTorch Dataset, Loader and model-specific preprocessing for CIFAR10 using Torchvision helpers\n",
    "2. Instantiate Pytorch model\n",
    "3. Validate the model in PyTorch\n",
    "4. Export model to ONNX and convert to OpenVINO IR format\n",
    "5. Validate the model in OpenVINO\n",
    "6. Quantize model using POT API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create PyTorch Dataset, Loader and model-specific preprocessing for CIFAR10 using Torchvision helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# define preprocessing steps for model\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# define data loaders for training and validation\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "# categories used in dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\eaidova/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validate the model in PyTorch\n",
    "\n",
    "Just run a loop over test dataset and compute a top-1 metric manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 72.17 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Export model to ONNX and convert to OpenVINO IR format\n",
    "\n",
    "We want to run model with OpenVINO framework. For that we need to convert it to IR using OpenVINO Model Optimizer tool. The best practice for PyTorch models to export them to ONNX before starting work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, images[0].unsqueeze(0), 'resnet20-cifar10.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.onnx\n",
      "\t- Path for generated IR: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\.\n",
      "\t- IR output name: \tresnet20-cifar10\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Use legacy API for model processing: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "\t- OpenVINO runtime found in: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\openvino\n",
      "OpenVINO runtime version: \t2022.1.0-6839-171ad9536fc\n",
      "Model Optimizer version: \t2022.1.0-6502-57b08583cc4\n",
      "[ WARNING ] Model Optimizer and OpenVINO runtime versions do no match.\n",
      "[ WARNING ] Consider building the OpenVINO Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino==2022.1\"\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: c:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.xml\n",
      "[ SUCCESS ] BIN file: c:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.bin\n",
      "[ SUCCESS ] Total execution time: 1.28 seconds. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n"
     ]
    }
   ],
   "source": [
    "!mo --input_model resnet20-cifar10.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validate the model in OpenVINO\n",
    "\n",
    "We wrap PyTorch preprocessing with OMZ helper and user a ready-to-use OMZ dataset class for CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation conversion for cifar10 dataset has been started\n",
      "Parameters to be used for conversion:\n",
      "converter: cifar\n",
      "data_batch_file: data\\cifar-10-batches-py\\test_batch\n",
      "convert_images: True\n",
      "converted_images_dir: data\\test\n",
      "num_classes: 10\n",
      "Annotation conversion for cifar10 dataset has been finished\n"
     ]
    }
   ],
   "source": [
    "from openvino.model_zoo.datasets import CIFAR10Dataset # is analog of data loader\n",
    "from openvino.model_zoo.transforms.input import from_torch # translater for torchvision transforms to openvino\n",
    "\n",
    "ov_transforms = from_torch(transform) # wrap our torchvision transforms\n",
    "test_loader = CIFAR10Dataset('./data', reader='pillow_imread')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_loader has a similar interface to tochvision. It allow access to dataset annotation and input data using integer index and iterate over samples. Optional step is appling transformations to input data.\n",
    "\n",
    "The data in iteration represented in following format `data, annotation` where:\n",
    "\n",
    "* input - input data\n",
    "* annotation - batch of labels for selected samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and set model specific transforms into dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "core = Core()\n",
    "model = core.read_model('resnet20-cifar10.xml')\n",
    "compiled_model = core.compile_model(model, 'CPU')\n",
    "output = compiled_model.outputs[0]\n",
    "infer_request = compiled_model.create_infer_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader.set_transforms([ov_transforms]) # set transformations for input data\n",
    "test_loader.set_input_info(model.inputs) # set transforms for feeding to model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a metric object and measure accuracy using OpenVINO inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.model_zoo.metrics import create_accuracy # [AK]: Can we replace this with the class similar to Torch Metrics?\n",
    "from openvino.model_zoo.transforms.output import ClassificationPostprocessor\n",
    "\n",
    "accuracy = create_accuracy()\n",
    "postprocess_transform = ClassificationPostprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data, annotation) in enumerate(test_loader): # [AK]: Plesase revise the interfaces for transforms and loader accordingly\n",
    "    infer_result = infer_request.infer(data[0])\n",
    "    predictions = postprocess_transform(infer_result)\n",
    "    accuracy.batch_update(predictions, annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8746\n"
     ]
    }
   ],
   "source": [
    "print(f'Model accuracy: {accuracy.evaluate()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Quantize model using POT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\Anaconda3\\envs\\py37\\lib\\site-packages\\defusedxml\\__init__.py:30: DeprecationWarning: defusedxml.cElementTree is deprecated, import from defusedxml.ElementTree instead.\n",
      "  from . import cElementTree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import addict\n",
    "from openvino.tools.pot import IEEngine, save_model, compress_model_weights, create_pipeline, load_model\n",
    "from openvino.tools.pot.engines.utils import process_raw_output\n",
    "\n",
    "# define configuration\n",
    "\n",
    "algorithms = [\n",
    "        {\n",
    "            'name': 'DefaultQuantization',\n",
    "            'params': {\n",
    "                'target_device': 'ANY',\n",
    "                'preset': 'mixed',\n",
    "                'stat_subset_size': 300\n",
    "            }\n",
    "        }\n",
    "]\n",
    "\n",
    "model_config = {\n",
    "        'model_name': 'sample_model',\n",
    "        'model': 'resnet20-cifar10.xml',\n",
    "        'weights': 'resnet20-cifar10.bin'\n",
    "}\n",
    "\n",
    "engine_config = {\n",
    "        'device': 'CPU',\n",
    "        'stat_requests_number': 4,\n",
    "        'eval_requests_number': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = IEEngine(engine_config, test_loader, accuracy)\n",
    "pipeline = create_pipeline(algorithms, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rep = load_model(model_config)\n",
    "compressed_model = pipeline.run(model_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'optimized\\\\resnet20-cifar10.xml',\n",
       "  'weights': 'optimized\\\\resnet20-cifar10.bin'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_model_weights(compressed_model)\n",
    "save_model(compressed_model, 'optimized', 'resnet20-cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results = pipeline.evaluate(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy: 9.36 %\n"
     ]
    }
   ],
   "source": [
    "for key, value in metric_results.items():\n",
    "    print(f'Quantized model {key}: {value * 100} %')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de7950e2c7f59756e69470654cad4361df158ed1ba671081876ae2b683d5c84"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
