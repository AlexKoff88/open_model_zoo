{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalize the CIFAR10 training and test datasets using torchvision\n",
    "2. Load Pytorch model\n",
    "3. Test the network on the test data\n",
    "4. Convert model to ONNX and OpenVINO IR format\n",
    "5. Evaluate converted model accuracy\n",
    "6. Optimize model to INT8 precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and normalize CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# define preprocessing steps for model\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# define data loaders for training and validation\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "# categories used in dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\eaidova/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test the network on the test data\n",
    "\n",
    "We have trained the network and need to check how well it performes on valikdation datat.\n",
    "\n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let us see what the neural network thinks these examples above are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, letâ€™s get the index of the highest energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 72.17 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert model to ONNX and OpenVINO IR format\n",
    "\n",
    "We want to run model with OpenVINO framework. For that we need to convert it to IR using OpenVINO Model Optimizer tool. The best practice for PyTorch models to export them to ONNX before starting work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, images[0].unsqueeze(0), 'resnet20-cifar10.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.onnx\n",
      "\t- Path for generated IR: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\.\n",
      "\t- IR output name: \tresnet20-cifar10\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Use legacy API for model processing: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "\t- OpenVINO runtime found in: \tc:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\openvino\n",
      "OpenVINO runtime version: \t2022.1.0-6839-171ad9536fc\n",
      "Model Optimizer version: \t2022.1.0-6502-57b08583cc4\n",
      "[ WARNING ] Model Optimizer and OpenVINO runtime versions do no match.\n",
      "[ WARNING ] Consider building the OpenVINO Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino==2022.1\"\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: c:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.xml\n",
      "[ SUCCESS ] BIN file: c:\\Users\\eaidova\\repos\\open_model_zoo\\data\\dataset_api\\resnet20-cifar10.bin\n",
      "[ SUCCESS ] Total execution time: 1.28 seconds. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n"
     ]
    }
   ],
   "source": [
    "!mo --input_model resnet20-cifar10.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate converted model accuracy\n",
    "\n",
    "Now we want to check how model works with OpenVINO. We already have dataset and transformation steps defined for PyTorch and need to adopt to work with OpenVINO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation conversion for cifar10 dataset has been started\n",
      "Parameters to be used for conversion:\n",
      "converter: cifar\n",
      "data_batch_file: data\\cifar-10-batches-py\\test_batch\n",
      "convert_images: True\n",
      "converted_images_dir: data\\test\n",
      "num_classes: 10\n",
      "Annotation conversion for cifar10 dataset has been finished\n"
     ]
    }
   ],
   "source": [
    "from openvino.model_zoo.datasets import CIFAR10Dataset # is analog of data loader\n",
    "from openvino.model_zoo.transforms.input import from_torch # translater for torchvision transforms to openvino\n",
    "\n",
    "ov_transforms = from_torch(transform) # wrap our torchvision transforms\n",
    "test_loader = CIFAR10Dataset('./data', reader='pillow_imread')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_loader has similar to tochvision interface, it allow access to dataset annotation and input data using integer index and iterate over samples. Optional step is appling transformations to input data\n",
    "\n",
    "The data in iteration represented in following format (batch_idx, batch_annotation), batch_input, batch_metadata, where:\n",
    "\n",
    "* batch_id - index of selected samples from dataset for data batch\n",
    "* batch_annotation - batch of labels for selected samples\n",
    "* batch_input - input data\n",
    "* batch_metadata - additional dictionary with useful meta for samples (it may contains e.g. info about dataset labels or preprocessing ops history for postprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and get it predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "core = Core()\n",
    "model = core.read_model('resnet20-cifar10.xml')\n",
    "compiled_model = core.compile_model(model, 'CPU')\n",
    "output = compiled_model.outputs[0]\n",
    "infer_request = compiled_model.create_infer_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader.set_transforms([ov_transforms]) # set transformations for input data\n",
    "test_loader.set_input_info(model.inputs) # set transforms for feeding to model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets calculate accuracy of converted network. For accuracy measurement we will use metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.model_zoo.metrics import create_accuracy\n",
    "from openvino.model_zoo.transforms.output import ClassificationPostprocessor\n",
    "\n",
    "accuracy = create_accuracy()\n",
    "postprocess_transform = ClassificationPostprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (batch_idx_batch_annotation, batch_input, batch_meta) in enumerate(test_loader):\n",
    "    batch_ids, batch_annotations = map(list, zip(*batch_idx_batch_annotation))\n",
    "    infer_result = infer_request.infer(batch_input[0])\n",
    "    batch_predictions = postprocess_transform(infer_result, batch_meta)\n",
    "    accuracy.batch_update(batch_annotations, batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8746\n"
     ]
    }
   ],
   "source": [
    "print(f'Model accuracy: {accuracy.evaluate()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, no accuracy degradation found during evaluation.\n",
    "Now, let try to optimize model via Posttraining Optimization tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\Anaconda3\\envs\\py37\\lib\\site-packages\\defusedxml\\__init__.py:30: DeprecationWarning: defusedxml.cElementTree is deprecated, import from defusedxml.ElementTree instead.\n",
      "  from . import cElementTree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import addict\n",
    "from openvino.tools.pot import IEEngine, save_model, compress_model_weights, create_pipeline, load_model\n",
    "from openvino.tools.pot.engines.utils import process_raw_output\n",
    "\n",
    "# define configuration\n",
    "\n",
    "algorithms = [\n",
    "        {\n",
    "            'name': 'DefaultQuantization',\n",
    "            'params': {\n",
    "                'target_device': 'ANY',\n",
    "                'preset': 'performance',\n",
    "                'stat_subset_size': 300\n",
    "            }\n",
    "        }\n",
    "]\n",
    "\n",
    "model_config = addict.Dict({\n",
    "        'model_name': 'sample_model',\n",
    "        'model': 'resnet20-cifar10.xml',\n",
    "        'weights': 'resnet20-cifar10.bin'\n",
    "})\n",
    "\n",
    "engine_config = addict.Dict({\n",
    "        'device': 'CPU',\n",
    "        'stat_requests_number': 4,\n",
    "        'eval_requests_number': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine(IEEngine):\n",
    "    def _process_infer_output(self, stats_layout, predictions,\n",
    "                              batch_annotations, batch_meta, need_metrics_per_sample):\n",
    "        # Collect statistics\n",
    "        if stats_layout:\n",
    "            self._collect_statistics(outputs=predictions,\n",
    "                                     stats_layout=stats_layout,\n",
    "                                     annotations=batch_annotations)\n",
    "\n",
    "        # Postprocess network output\n",
    "        outputs = process_raw_output(predictions)\n",
    "        postprocess_transform.output_tensor = str(self._output_layers[0])\n",
    "        # Update metrics\n",
    "        if batch_annotations:\n",
    "            batch_predictions = postprocess_transform(outputs)\n",
    "\n",
    "            self._update_metrics(batch_predictions, annotations=batch_annotations,\n",
    "                                 need_metrics_per_sample=need_metrics_per_sample)\n",
    "\n",
    "    def _update_metrics(self, output, annotations, need_metrics_per_sample=False):\n",
    "        \"\"\" Updates metrics.\n",
    "        :param output: network output\n",
    "        :param annotations: a list of annotations for metrics collection [(img_id, annotation)]\n",
    "        :param need_metrics_per_sample: whether to collect metrics for each batch\n",
    "        \"\"\"\n",
    "        annotations_are_valid = all(a is not None for a in annotations)\n",
    "\n",
    "        if self._metric and annotations_are_valid:\n",
    "            sample_ids, batch_annotations = map(list, zip(*batch_idx_batch_annotation))\n",
    "            metrics = self._metric.batch_update(batch_annotations, output)\n",
    "            if need_metrics_per_sample:\n",
    "                metrics = self._metric.value\n",
    "                for sample_id, metric in zip(sample_ids, metrics):\n",
    "                    for metric_name, metric_value in metric.items():\n",
    "                        self._per_sample_metrics.append({'sample_id': sample_id,\n",
    "                                                'metric_name': metric_name,\n",
    "                                                'result': metric_value})\n",
    "\n",
    "    def _process_batch(self, batch):\n",
    "        _batch = batch[0]\n",
    "        batch_annotation, batch_input, batch_meta = _batch[0], _batch[1], _batch[2]\n",
    "\n",
    "        return batch_annotation, batch_input, batch_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = Engine(engine_config, test_loader, accuracy)\n",
    "pipeline = create_pipeline(algorithms, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rep = load_model(model_config)\n",
    "compressed_model = pipeline.run(model_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'optimized\\\\resnet20-cifar10.xml',\n",
       "  'weights': 'optimized\\\\resnet20-cifar10.bin'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_model_weights(compressed_model)\n",
    "save_model(compressed_model, 'optimized', 'resnet20-cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results = pipeline.evaluate(compressed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy: 9.36 %\n"
     ]
    }
   ],
   "source": [
    "for key, value in metric_results.items():\n",
    "    print(f'Quantized model {key}: {value * 100} %')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de7950e2c7f59756e69470654cad4361df158ed1ba671081876ae2b683d5c84"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
